{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPteAqlJEYqPTCdw9WY6LFt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Mobile Net"],"metadata":{"id":"byPl7CD546qb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IjyGO0_Q4ibg"},"outputs":[],"source":["# Install necessary libraries\n","import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","import tensorflow as tf\n","from tensorflow.keras.applications import MobileNet\n","from tensorflow.keras.applications.mobilenet import preprocess_input\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n","from tensorflow.keras.optimizers import Adam\n","import matplotlib.pyplot as plt\n","\n","# Helper function to load and preprocess images\n","def load_and_preprocess_images(image_paths, target_size=(224, 224)):\n","    images = []\n","    for img_path in image_paths:\n","        image = cv2.imread(img_path)\n","        if image is not None:\n","            image = cv2.resize(image, target_size)  # Resize to match MobileNet input\n","            image = preprocess_input(image)  # Preprocess for MobileNet\n","            images.append(image)\n","    return np.array(images)\n","\n","# Define paths and reference card details\n","test_images_path = '/content/drive/MyDrive/dataset/test_images'  # Update with test images path\n","dataset_path = '/content/drive/MyDrive/course data( all files needed for students )/Anemia_dataset_train.xlsx'  # dataset path\n","\n","# Load Hb_Value and prepare dataset\n","print(\"Loading Hb_Value data...\")\n","right_eye_data = pd.read_excel(dataset_path, sheet_name='Right_Eye_Data')\n","\n","# Match images with Hb values using filenames\n","print(\"Matching image filenames with Hb values...\")\n","image_filenames = os.listdir(test_images_path)\n","hb_filenames = right_eye_data[\"Right_eye_Images\"]  # Adjust this to the actual column containing image filenames\n","\n","# Filter valid entries\n","valid_image_paths = []\n","valid_hb_values = []\n","\n","for img in image_filenames:\n","    if img in hb_filenames.values:\n","        valid_image_paths.append(os.path.join(test_images_path, img))\n","        valid_hb_values.append(right_eye_data.loc[right_eye_data[\"Right_eye_Images\"] == img, \"Hb_Value\"].values[0])\n","\n","# Check for missing files\n","missing_files = [filename for filename in hb_filenames if filename not in image_filenames]\n","if missing_files:\n","    print(f\"Warning: Missing files detected! {missing_files}\")\n","\n","# Preprocess valid images\n","print(\"Preprocessing valid images...\")\n","images = load_and_preprocess_images(valid_image_paths)\n","hb_values = pd.Series(valid_hb_values)  # Convert to a Pandas Series for compatibility\n","\n","# Split data into training and testing sets\n","print(\"Splitting data into training and testing sets...\")\n","X_train, X_test, y_train, y_test = train_test_split(images, hb_values, test_size=0.2, random_state=42)\n","\n","# Load MobileNet model for feature extraction\n","print(\"Loading MobileNet model...\")\n","base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# Build the model\n","model = Sequential([\n","    base_model,\n","    GlobalAveragePooling2D(),  # Pooling layer\n","    Dropout(0.3),  # Prevent overfitting\n","    Dense(128, activation='relu'),  # Fully connected layer\n","    Dropout(0.3),\n","    Dense(1, activation='linear')  # Single output for Hb value prediction\n","])\n","\n","# Compile the model\n","print(\"Compiling the model...\")\n","model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse', metrics=['mae'])\n","\n","# Train the model\n","print(\"Training the model...\")\n","history = model.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=100,\n","    batch_size=16,\n","    verbose=1\n",")\n","\n","# Evaluate the model\n","print(\"Evaluating the model...\")\n","y_pred = model.predict(X_test).flatten()\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = mse ** 0.5\n","mae = np.mean(np.abs(y_test - y_pred))  # Calculate Mean Absolute Error\n","r2 = r2_score(y_test, y_pred)\n","\n","print(f\"RMSE: {rmse}\")\n","print(f\"MSE: {mse}\")\n","print(f\"MAE: {mae}\")\n","print(f\"R² Score: {r2}\")\n","\n","\n","# Plot training history\n","plt.figure(figsize=(10, 6))\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Plot Actual vs Predicted Hb Values\n","plt.figure(figsize=(10, 6))\n","plt.scatter(y_test, y_pred, alpha=0.7, label=\"Predicted vs Actual\")\n","plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color=\"red\", linestyle=\"--\", label=\"Ideal Fit\")\n","plt.title(\"Actual vs Predicted Hb Values\")\n","plt.xlabel(\"Actual Hb Value\")\n","plt.ylabel(\"Predicted Hb Value\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Residual Plot\n","residuals = y_test - y_pred\n","plt.figure(figsize=(10, 6))\n","plt.scatter(y_pred, residuals, alpha=0.7, label=\"Residuals\")\n","plt.axhline(0, color=\"red\", linestyle=\"--\", label=\"Zero Error Line\")\n","plt.title(\"Residual Plot\")\n","plt.xlabel(\"Predicted Hb Value\")\n","plt.ylabel(\"Residual (Actual - Predicted)\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Save predictions to a CSV file\n","output_path = '/content/mobilenet_predictions.csv'\n","results_df = pd.DataFrame({\n","    \"Actual_Hb_Value\": y_test,\n","    \"Predicted_Hb_Value\": y_pred\n","})\n","results_df.to_csv(output_path, index=False)\n","print(f\"Predictions saved to {output_path}\")"]},{"cell_type":"markdown","source":["# Efficient Net"],"metadata":{"id":"A_lAltoX42pq"}},{"cell_type":"code","source":["# Install necessary libraries\n","import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","import tensorflow as tf\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.applications.efficientnet import preprocess_input\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n","from tensorflow.keras.optimizers import Adam\n","import matplotlib.pyplot as plt\n","\n","# Helper function to load and preprocess images\n","def load_and_preprocess_images(image_paths, target_size=(224, 224)):\n","    images = []\n","    for img_path in image_paths:\n","        image = cv2.imread(img_path)\n","        if image is not None:\n","            image = cv2.resize(image, target_size)  # Resize to match EfficientNet input\n","            image = preprocess_input(image)  # Preprocess for EfficientNet\n","            images.append(image)\n","    return np.array(images)\n","\n","# Define paths and reference card details\n","test_images_path = '/content/drive/MyDrive/dataset/test_images'  # Update with test images path\n","dataset_path = '/content/drive/MyDrive/course data( all files needed for students )/Anemia_dataset_train.xlsx'  # dataset path\n","\n","# Load Hb_Value and prepare dataset\n","print(\"Loading Hb_Value data...\")\n","right_eye_data = pd.read_excel(dataset_path, sheet_name='Right_Eye_Data')\n","\n","# Match images with Hb values using filenames\n","print(\"Matching image filenames with Hb values...\")\n","image_filenames = os.listdir(test_images_path)\n","hb_filenames = right_eye_data[\"Right_eye_Images\"]  # Adjust this to the actual column containing image filenames\n","\n","# Filter valid entries\n","valid_image_paths = []\n","valid_hb_values = []\n","\n","for img in image_filenames:\n","    if img in hb_filenames.values:\n","        valid_image_paths.append(os.path.join(test_images_path, img))\n","        valid_hb_values.append(right_eye_data.loc[right_eye_data[\"Right_eye_Images\"] == img, \"Hb_Value\"].values[0])\n","\n","# Check for missing files\n","missing_files = [filename for filename in hb_filenames if filename not in image_filenames]\n","if missing_files:\n","    print(f\"Warning: Missing files detected! {missing_files}\")\n","\n","# Preprocess valid images\n","print(\"Preprocessing valid images...\")\n","images = load_and_preprocess_images(valid_image_paths)\n","hb_values = pd.Series(valid_hb_values)  # Convert to a Pandas Series for compatibility\n","\n","# Split data into training and testing sets\n","print(\"Splitting data into training and testing sets...\")\n","X_train, X_test, y_train, y_test = train_test_split(images, hb_values, test_size=0.2, random_state=42)\n","\n","# Load EfficientNet model for feature extraction\n","print(\"Loading EfficientNet model...\")\n","base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# Build the model\n","model = Sequential([\n","    base_model,\n","    GlobalAveragePooling2D(),  # Pooling layer\n","    Dropout(0.3),  # Prevent overfitting\n","    Dense(128, activation='relu'),  # Fully connected layer\n","    Dropout(0.3),\n","    Dense(1, activation='linear')  # Single output for Hb value prediction\n","])\n","\n","# Compile the model\n","print(\"Compiling the model...\")\n","model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse', metrics=['mae'])\n","\n","# Train the model\n","print(\"Training the model...\")\n","history = model.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs= 100,\n","    batch_size=16,\n","    verbose=1\n",")\n","\n","# Evaluate the model\n","print(\"Evaluating the model...\")\n","y_pred = model.predict(X_test).flatten()\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = mse ** 0.5\n","mae = np.mean(np.abs(y_test - y_pred))  # Calculate Mean Absolute Error\n","r2 = r2_score(y_test, y_pred)\n","\n","print(f\"RMSE: {rmse}\")\n","print(f\"MSE: {mse}\")\n","print(f\"MAE: {mae}\")\n","print(f\"R² Score: {r2}\")\n","\n","# Plot training history\n","plt.figure(figsize=(10, 6))\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Plot Actual vs Predicted Hb Values\n","plt.figure(figsize=(10, 6))\n","plt.scatter(y_test, y_pred, alpha=0.7, label=\"Predicted vs Actual\")\n","plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color=\"red\", linestyle=\"--\", label=\"Ideal Fit\")\n","plt.title(\"Actual vs Predicted Hb Values\")\n","plt.xlabel(\"Actual Hb Value\")\n","plt.ylabel(\"Predicted Hb Value\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Residual Plot\n","residuals = y_test - y_pred\n","plt.figure(figsize=(10, 6))\n","plt.scatter(y_pred, residuals, alpha=0.7, label=\"Residuals\")\n","plt.axhline(0, color=\"red\", linestyle=\"--\", label=\"Zero Error Line\")\n","plt.title(\"Residual Plot\")\n","plt.xlabel(\"Predicted Hb Value\")\n","plt.ylabel(\"Residual (Actual - Predicted)\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Save predictions to a CSV file\n","output_path = '/content/efficientnet_predictions.csv'\n","results_df = pd.DataFrame({\n","    \"Actual_Hb_Value\": y_test,\n","    \"Predicted_Hb_Value\": y_pred\n","})\n","results_df.to_csv(output_path, index=False)\n","print(f\"Predictions saved to {output_path}\")\n"],"metadata":{"id":"LqvZko984vLM"},"execution_count":null,"outputs":[]}]}